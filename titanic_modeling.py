# -*- coding: utf-8 -*-
"""titanic_modeling

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FvXvD-ki4BER3glGKQ-VCjEjcKHvxMUj

# Summary

This notebook explores the Titanic dataset and builds a model to predict the survival rate of the passengers.

# Libraries and Packages
"""

import numpy as np
import pandas as pd
from matplotlib import pyplot as plt

titanic = pd.read_csv('/content/Titanic.csv')

"""# Exploratory Data Analysis"""

print("Dataset shape:", titanic.shape)

titanic.info()

titanic.columns = titanic.columns.str.lower()

titanic.survived.value_counts(normalize=True)

titanic[titanic.age.notnull()].survived.value_counts(normalize=True)

titanic['cabin_letter'] = titanic['cabin'].apply(lambda x: str(x)[:1] if type(x) is not float else np.nan)

"""# Feature Selection"""

titanic.columns

titanic.embarked.unique()

features = ['survived', 'pclass', 'sex',
            'age', 'parch', 'embarked',
            'fare', 'sibsp']
titanic_features = titanic[features]

titanic_features.info()

titanic_features = titanic_features.dropna().reset_index(drop=True)

cat_vars = ['pclass', 'sex', 'embarked']
titanic_features = pd.get_dummies(titanic_features, columns=cat_vars)

"""# Train-Test Split"""

X = titanic_features[titanic_features.columns[1:]] # get all the features without the `survived`
y = titanic_features.survived

from sklearn.model_selection import train_test_split

# Assuming 'X' is your feature matrix and 'y' is your target variable
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)

"""# Modeling"""

# Import necessary libraries and models
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC

# Instantiate the models
# log_reg = LogisticRegression()
random_forest = RandomForestClassifier()
naive_bayes = GaussianNB()
svc = SVC()

# Fit each model on the training data
# log_reg.fit(X_train, y_train)
random_forest.fit(X_train, y_train)
naive_bayes.fit(X_train, y_train)
svc.fit(X_train, y_train)

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc

# Assuming you already have X_test, y_test, and the models fitted

# Importing roc_curve from sklearn.metrics
from sklearn.metrics import roc_curve

# Logistic Regression: predict_proba
# log_reg_proba = log_reg.predict_proba(X_test_scaled)[:, 1]  # Probability estimates for the positive class

# Random Forest: predict_proba
random_forest_proba = random_forest.predict_proba(X_test)[:, 1]

# Naive Bayes: predict_proba
naive_bayes_proba = naive_bayes.predict_proba(X_test)[:, 1]

# SVC: Use decision_function instead of predict_proba
svc_proba = svc.decision_function(X_test)

# Calculate ROC curve for each model
# fpr_log, tpr_log, _ = roc_curve(y_test, log_reg_proba)
fpr_rf, tpr_rf, _ = roc_curve(y_test, random_forest_proba)
fpr_nb, tpr_nb, _ = roc_curve(y_test, naive_bayes_proba)
fpr_svc, tpr_svc, _ = roc_curve(y_test, svc_proba)

# Calculate AUC for each model
# roc_auc_log = auc(fpr_log, tpr_log)
roc_auc_rf = auc(fpr_rf, tpr_rf)
roc_auc_nb = auc(fpr_nb, tpr_nb)
roc_auc_svc = auc(fpr_svc, tpr_svc)

# Plotting the ROC curves
plt.figure(figsize=(8, 6))
# plt.plot(fpr_log, tpr_log, label=f'Logistic Regression (AUC = {roc_auc_log:.2f})')
plt.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {roc_auc_rf:.2f})')
plt.plot(fpr_nb, tpr_nb, label=f'Naive Bayes (AUC = {roc_auc_nb:.2f})')
plt.plot(fpr_svc, tpr_svc, label=f'SVC (AUC = {roc_auc_svc:.2f})')

# Plot formatting
plt.plot([0, 1], [0, 1], 'k--', lw=2)  # Diagonal line representing random chance
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curves for Different Models')
plt.legend(loc="lower right")
plt.grid()
plt.show()

from sklearn.metrics import precision_recall_curve, accuracy_score, average_precision_score

# Random Forest: predict_proba
random_forest_proba = random_forest.predict_proba(X_test)[:, 1]
random_forest_pred = random_forest.predict(X_test)

# Naive Bayes: predict_proba
naive_bayes_proba = naive_bayes.predict_proba(X_test)[:, 1]
naive_bayes_pred = naive_bayes.predict(X_test)

# SVC: Use decision_function instead of predict_proba
svc_proba = svc.decision_function(X_test)
svc_pred = svc.predict(X_test)

# Calculate precision-recall curve for each model
precision_rf, recall_rf, _ = precision_recall_curve(y_test, random_forest_proba)
precision_nb, recall_nb, _ = precision_recall_curve(y_test, naive_bayes_proba)
precision_svc, recall_svc, _ = precision_recall_curve(y_test, svc_proba)

# Calculate accuracy for each model
accuracy_rf = accuracy_score(y_test, random_forest_pred)
accuracy_nb = accuracy_score(y_test, naive_bayes_pred)
accuracy_svc = accuracy_score(y_test, svc_pred)

# Calculate average precision score for each model
ap_rf = average_precision_score(y_test, random_forest_proba)
ap_nb = average_precision_score(y_test, naive_bayes_proba)
ap_svc = average_precision_score(y_test, svc_proba)

# Print accuracy rates
print(f"Random Forest Accuracy: {accuracy_rf:.2f}")
print(f"Naive Bayes Accuracy: {accuracy_nb:.2f}")
print(f"SVC Accuracy: {accuracy_svc:.2f}")

# Plotting Precision-Recall Curves
plt.figure(figsize=(8, 6))
plt.plot(recall_rf, precision_rf, label=f'Random Forest (AP = {ap_rf:.2f})')
plt.plot(recall_nb, precision_nb, label=f'Naive Bayes (AP = {ap_nb:.2f})')
plt.plot(recall_svc, precision_svc, label=f'SVC (AP = {ap_svc:.2f})')

# Plot formatting
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curves with Average Precision')
plt.legend(loc="lower left")
plt.grid()
plt.show()

